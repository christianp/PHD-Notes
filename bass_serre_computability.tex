\documentclass[a4paper]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{upgreek}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage[usenames,dvipsnames]{color}
\usepackage{setspace}
\singlespacing
%\onehalfspacing
%\doublespacing
%\setstretch{1.1}

\parskip 2ex
\parindent 0pt

\newcommand{\grz}[1]{$\mathcal{E}^{#1}$}	%grzegorczyk level

\newcommand{\NN}{\mathbb{N}}	%blackboard bold
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand\ov[1]{\overline{#1}} %overline
\newcommand{\maps}{\longrightarrow}

\newcommand\eps{\varepsilon}

\newcommand{\nth}{$n^{\textrm{th}}$~}	% nth and ith typeset nicely
\newcommand{\ith}{$i^{\textrm{th}}$~}

\newcommand{\shortlex}{{\sf ShortLex}\;}	% shortlex ordering has a sans-serif brand identity

\newcommand{\avec}{\mathbf{a}}	% vector
\newcommand{\bvec}{\mathbf{b}}	% vector 
\newcommand{\cvec}{\mathbf{c}}	% vector 
\newcommand{\dvec}{\mathbf{d}}	% vector 
\newcommand{\uvec}{\mathbf{u}}	% vector 
\newcommand{\vvec}{\mathbf{v}}	% vector 
\newcommand{\wvec}{\mathbf{w}}	% vector w
\newcommand{\xvec}{\mathbf{x}}	% vector x
\newcommand{\yvec}{\mathbf{y}}	% vector y
\newcommand{\zvec}{\mathbf{z}}	% vector 
\newcommand{\tvec}{\mathbf{t}}	% vector t
\newcommand{\Uvec}{\mathbf{U}}	% vector U
\newcommand{\psub}{\dot -}	% proper subtraction
\newcommand{\rsg}{\overline{sg}} % reverse signature
\newcommand{\recur}[1]{\begin{equation} \begin{split} #1 \end{split} \end{equation}}	%definition of recursive function
\newcommand{\recurN}[1]{\begin{equation*} \begin{split} #1 \end{split} \end{equation*}}	%ditto, no equation number

\newcommand{\classC}{$\mathcal{C}$}

\newcommand{\concat}{\ensuremath{+\!\!\!\!+\,}}	% list concatenation

\newcommand{\present}[2]{\left \langle #1 \: | \: #2 \right \rangle}	%group presentation
\newcommand{\fgoagog}{\pi_1(\mathbf{G},\Gamma,T,v_0)}	%fundamental group of a graph of groups
%universal group of a pregroup P
\newcommand{\UP}{\Uvec(P)}

%%% sets { ... | ... }
\newcommand{\set}[2]{\left\{\, \mathinner{#1}\vphantom{#2}\; \left|\; \vphantom{#1}\mathinner{#2} \right.\,\right\}}
\newcommand{\oneset}[1]{\left\{\, \mathinner{#1} \,\right\}}
\newcommand{\smallset}[1]{\left\{\mathinner{#1}\right\}}
%%%%%%%%%%%% brackets etc
\newcommand{\abs}[1]{\left|\mathinner{#1}\right|}
\newcommand{\floor}[1]{\left\lfloor\mathinner{#1} \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil\mathinner{#1} \right\rceil}
\newcommand{\bracket}[1]{\left[\mathinner{#1} \right]}
\newcommand{\parenth}[1]{\left(\mathinner{#1} \right)}
\newcommand{\gen}[1]{\left< \mathinner{#1} \right>}

\newcommand{\rdeg}[1]{\mbox{red-deg}\left(\mathinner{#1}\right)}
%%%%%%%%%%%%%functions
\newcommand{\find}{\operatorname{find}}
\newcommand{\Dfind}{\operatorname{Dfind}}
\newcommand{\Preduced}{\operatorname{Preduced}}
\newcommand{\leftm}{\operatorname{leftm}}
\newcommand{\Predn}{\operatorname{Predn}}
\newcommand{\Preduction}{\operatorname{Preduction}}
\newcommand{\Interleaven}{\operatorname{Interleaven}}

\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]

\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}

\newenvironment{myproof}{\normalsize {\sc Proof}:}{{\hfill $\Box$}}

\newenvironment{cpe}{\noindent\color{OliveGreen} CP }{}
\newcommand{\cp}[1]{
\begin{cpe} #1 \end{cpe}}
%%
\newenvironment{ad}{\noindent\color{blue} AJD }{}
\newcommand{\ajd}[1]{
\begin{ad} #1 \end{ad}}
%%
\begin{document}
\title{Computability of Bass-Serre structures}
\author{Christian Perfect \and Andrew Duncan}
\maketitle

\section*{Introduction}

Grzegorczyk \cite{Grzegorczyk_1953} introduced a hierarchy of classes of recursive functions delineated by the number of times unbounded recursion is used in the construction of their members. Following Rabin \cite{Rabin_1960}, Cannonito \cite{Cannonito_1966} defined a notion of computability for groups in the context of this hierarchy. Cannonito and Gatterdam \cite{Cannonito_1973} \cite{Gatterdam_1973} showed that, when taking a free product with amalgamation or an HNN extension of group(s) represented by functions computable at a particular level of the hierarchy, one creates a group with corresponding functions computable at most one level higher.

We describe the Grzegorczyk hierarchy and present a clear notation for defining functions within it, along with constructions of many useful elementary functions. 

Section \ref{buildingblocks} defines the notation used in this paper. Section \ref{grzegorczyk} defines the Grzegorczyk hierarchy of computable functions and gives definitions and positions on the hierarchy for many useful functions. Section \ref{graphs} repeats Serre's \cite{Serre_1977} formulation of graphs, and Section \ref{trees} gives conditions for a tree to be computable at a certain level of the Grzegorczyk hierarchy.

In section \ref{groups} we restate \cite{Cannonito_1966}'s definition of an \grz{n}-computable group and \grz{3}-computable index of the free group on countably many generators. 

Section \ref{bass-serre} consists of a statement and proof of the main result of this paper -- that the fundamental group of a graph of \grz{n} groups is \grz{n+1}-computable, generalising the results of \cite{Cannonito_1973}. Additionally, we show that the fundamental group of a graph of finitely-generated \grz{n}-computable groups is also \grz{n}-computable, and give an example of a graph of \grz{3}-computable groups whose fundamental group is at least \grz{4}-computable.

Finally, Section \ref{sec:pregroup} defines computability for Stallings' pregroups \cite{Stallings_1971} in the context of the Grzegorczyk hierarchy, generalising the results above.


\section{Building blocks \label{buildingblocks}}
 
\subsection{Notation}
Expressions consist of operators, function names, variables and punctuation. 
When defining expressions or new notation, $E \equiv E' := D$ means we will write $E$ or $E'$ to mean $D$.

\subsection{Constructing functions}
Let $\ZZ_{\geq 0}$ denote the non-negative integers. A function $f$, taking $n$ arguments and resulting in a single value, is a map,
\[f: \ZZ_{\geq 0}^n \rightarrow \ZZ_{\geq 0}.\]

Usually we will write the expression $f(x_1, \dots, x_n)$ to mean ``the application of $f$ to the arguments $x_1,\dots,x_n$.''

Functions in general can take any number of arguments, so it is clearly impractical to write out definitions of each operation for each possible arity. When the arity of a function $f$ doesn't matter, we will write it as $f(\xvec)$, where $\xvec$ can represent an arbitrarily big vector.  When a function has to take at least a specific number of arguments $y_1, \dots, y_n$, and potentially more, we will write something of the form $f(\xvec, y_1, \dots, y_n)$.

\subsubsection{The primitive functions}

We will begin by defining the {\it primitive functions}, which are functions of one of the following three types:

\begin{itemize}
	\item {\em The zero function}. The zero function  is a nullary function which returns the number $0$. For brevity we will write the digit $0$ to mean the zero function, instead of using the function notation with brackets defined above.
	\item {\em The successor function}. The successor function $s(x) := x + 1$ is a unary function which adds $1$ to its input.
	\item {\em The projection functions}. For every $n > 0 $ and every $1 \leq i \leq n$ there is a projection function $P_n^i(x_1, \dots, x_n) := x_i$. $P_n^i$ is an $n$-ary function which returns its \ith argument.
\end{itemize}

There are two operations we shall use to create new functions from these primitives.

\subsubsection{Composition} 

Given an $n$-ary function $f$ and $m$-ary functions $g_1, \dots, g_n$, the {\it composition} operator $C$ constructs a new $m$-ary function $h$, where

\[ h(\xvec) = f(g_1(\xvec),\dots, g_n(\xvec)) := C(f,g_1, \dots, g_n)(\xvec). \]

If $f$ is unary, a function $h$ constructed by composition of $f$ with another function $g$ is denoted $h = f \circ g$ where

\[f \circ g(\xvec) \equiv f(g(\xvec)) := C(f,g)(\xvec).\] 

We will omit the generalised arguments for most function definitions, like so:

\begin{eqnarray*}
	f \circ g &:=& C(f,g), \\
	f(g_1, \dots, g_n) &:=& C(f,g_1, \dots, g_n).
\end{eqnarray*}

The mixing of functions of different arities can be dealt with systematically. For every $n$-ary function $f$, and every $m > n$, we can define an $m$-ary function $f_m$, 
\[f_m := C(f,P_m^1, \dots, P_m^n),\]
such that, for all $x_1, \dots, x_m$, $f_m(x_1, \dots, x_n, \dots, x_m) \equiv f(x_1, \dots, x_n)$.

Substitution of functions for parameters can also be dealt with systematically, by composing with the projection function $P_i^i$ everywhere except at the position which will take the value of the substituted function.

Suppose we have two $n$-ary functions $f(x_1,\dots,x_n)$ and $g(x_1,\dots,x_n)$. The function \[f(x_1,\dots,x_{i-1},g(x_1,\dots,x_n),x_{i+1},\dots,x_n),\] which computes $f$ with its $i^{\textrm{th}}$ parameter replaced by $g(x_1,\dots,x_n)$, is constructed like so:
\[f(x_1,\dots,x_{i-1},g(x_1,\dots,x_n),x_{i+1},\dots,x_n) := C(f,P_n^1,\dots,P_n^{i-1},g,P_n^{i+1},\dots,P_n^n).\]



\subsubsection{Recursion}

A function $h$ is constructed by {\it recursion} from functions $f$ and $g$ if

\begin{eqnarray*}
	h(\xvec,0) & := & f(\xvec), \\
	h(\xvec,n+1) & := & g(n,h(\xvec,n),\xvec),
\end{eqnarray*} 

in which case we write $h = R(f,g)$.

Note that the argument of recursion $n$ can be made to be in any position by composition with the projection functions. If we have a function $h(x_1,\dots,x_m,n)$, we can define a new function,
\[ f'(x_1, \dots, x_k, n, x_{k+1}, \dots, x_m) := C(f, P_{m+1}^1, \dots, P_{m+1}^k, P_{m+1}^{k+2},\dots, P_{m+1}^m, P_{m+1}^{k+1}), \]
so that 
\[ f'(x_1, \dots, x_k, n, x_{k+1}, \dots, x_m) := f(x_1, \dots, x_m, n). \\ \]

\subsection{Further notation}

\subsubsection{Parameters}
A {\it parameter} is a variable which is used in the definition of a function, not during evaluation. For instance, in the projection function $P_n^i$, $n$ and $i$ are parameters -- there is a different function for each pair of values $(n,i)$. Parameters do not count towards the arity of a function.

\subsubsection{Iteration}
A function which evaluates $n$ iterations of a function $f$, where $n$ is a parameter, can be constructed by composing $f$ with itself $n-1$ times.
\[f^{(n)}(\xvec) := \underbrace{C(f,C(f,C(f, \dots C(f,f}_{n-1 \textrm{ compositions}}) )(\xvec).\]

\subsubsection{Infix operators}
When using infix notation, binary operators are written between their operands.

For a binary function $f_{\ast}$, representing the operation $\ast$, we will use $x \ast y$ to denote $f_{\ast}(x,y)$, whenever the former notation is more conventional.

\[x \ast y := f_{\ast}(x,y). \]

\subsubsection{Sets}
A set $S \subseteq \ZZ_{\geq 0}^d$ is defined by its characteristic function $\chi_S$.
\[\chi_S(\xvec) := \begin{cases}
 1 & \xvec \in S, \\
 0 & \xvec \notin S.
 \end{cases}
\]

An {\it indexing} of a set $X$ is an injective function
\[ i : X \rightarrow Z_{\geq 0}. \]

\subsubsection{Relations}
A {\it $d$-ary relation on $\ZZ_{\geq 0}$} is
a subset $R$ of $\ZZ_{\geq 0}^d$, so is defined by its characteristic
function $\chi_R$. In addition, for binary relations we will write
\[ x R y := \chi_R(x,y). \]

\subsubsection{Logic}
The concept of falsity will be represented by the number $0$, and all other values will represent truth. With this in mind, predicates $P(\xvec)$ can be written out as ordinary functions once the logical operations have been defined.

\section{The Grzegorczyk hierarchy \label{grzegorczyk}}
A class \classC{}  is {\it closed under finite composition} if, whenever $f, g_1, \dots, g_m$ all belong to \classC{}, then $C(f,g_1, \dots, g_m)$ also belongs to \classC{}. In this case a function defined by finitely many compositions of elements of \classC{} is also an element of \classC{}.

A function $f$ is said to be {\it bounded} by another function $g$ if, for all $\xvec$, $f(\xvec) < g(\xvec)$.

A class \classC{} is {\it closed under bounded recursion} if, whenever $f,g,h$ belong to \classC{} and $R(f,g)(\xvec)$ is bounded by $h(\xvec)$, then $R(f,g)$ also belongs to \classC{}. If, for some $f$ and $g$, there is no such $h \in \mathcal{C}$ bounding $R(f,g)$, then $R(f,g)$ is said to be obtained by an {\it unbounded recursion} on $f$ and $g$.

The {\it Grzegorczyk hierarchy} is an infinite nested hierarchy of classes \grz{n} of functions which are each closed under finite composition and by bounded recursion. 

\grz{0} consists of just the primitive functions, and whatever else can be obtained by finitely many applications of the composition operator and bounded recursion.

\grz{n+1}, for $n \geq 0$, is the smallest class which

\begin{itemize}
	\item contains all of \grz{n};
	\item contains every function obtained by a single unbounded recursion on \grz{n} functions;
	\item is closed under finite composition and bounded recursion.
\end{itemize}

\begin{definition}
We say a function $f$ is {\it \grz{n}-computable} iff $f$ belongs to \grz{n}. Similarly, a set $S$ is said to be {\it \grz{n}-decidable} iff its characteristic function $\chi_S$ is \grz{n}-computable.

An indexing $i: X \rightarrow Z_{\geq 0}$ is said to be \grz{n}-decidable iff its image is \grz{n}-decidable.

\end{definition}

It can be difficult to determine whether a particular function belongs to a particular level of the hierarchy. A definition of the Grzegorczyk hierarchy equivalent to the one given above uses a sequence of hierarchy functions which bound the classes \grz{n}. We repeat Rose's \cite{Rose_1984} definitions and Lemmas on the subject here.

\begin{definition} \cite{Rose_1984}
The sequence of primitive recursive functions $E_n$ ($n=0,1,2,\dots$) is defined by
\begin{align*}
	E_0(x,y) &= x+y, \\
	E_1(x) &= x^2+2, \\
	E_{n+2}(0) &= 2, \\
	E_{n+2}(x+1) &= E_{n+1}(E_{n+2}(x)).
\end{align*}
\end{definition}

\begin{definition} \cite{Rose_1984}
	Paraphrasing Rose, for each $n \ge 0$, \grz{n+1} is the smallest class which contains \grz{n} plus the function $E_n$, and is closed under composition and bounded recursion.
\end{definition}

\begin{lemma} \cite[Lemma 2.2.5]{Rose_1984}
	Every function \grz{0}-computable function $f$ satisfies
	\[ f(x_1, \dots, x_n) \leq x_i + k, \]
	for some integers $k$ and $i$ where $1 \leq i \leq n$.
\end{lemma}

\begin{lemma} \cite[Lemma 2.2.6]{Rose_1984}
	If $f$ is an $n$-ary function in \grz{1} there are integers $a_0,a_1, \dots,a_n$ such that
	\[f(x_1,\dots,x_n) \leq a_0 + a_1 \cdot x_1 + a_2 \cdot x_2 + \dots + a_n \cdot x_n. \]
	That is, every \grz{1}-computable function is bounded by a linear combination of its arguments.
\end{lemma}

\begin{lemma} \cite[Lemma 2.2.7]{Rose_1984}
	If $f$ is an $n$-ary function in \grz{2} there is a polynomial $p$ in $n$ variables with the property
	\[f(x_1, \dots,x_n) \leq p(x_1, \dots, x_n). \]
\end{lemma}

\begin{lemma} \cite[Lemma 2.2.9]{Rose_1984}
	If $f$ is a $k$-ary function in \grz{n} and $n \geq 2$ then there is an integer $m$ such that
	\[f(x_1, \dots, x_k) \leq E_{n-1}^{(m)}(\max(x_1, \dots, x_k)).\]
\end{lemma}

\subsection{The stockpile of functions}
Below we will give explicit definitions for the operations of elementary arithmetic, plus some other useful things, using the notation defined above.
These functions all appear, though not always in the same notation, in
Kleene's list of primitive recursive functions, Sections 44 and 45 of 
\cite{Kleene52}. Here   
we have tried to use definitions which, though not necessarily 
the most obvious, place functions as low down on the hierarchy as possible. 

\subsection{\grz{0} functions}
For a constant integer $n$, we can construct a function to add $n$ to $x$ by iterating the successor function $n$ times on $x$:
\begin{equation} +_n(x) \equiv x + n := s^{(n)}(x). \end{equation}

Note that $n$ is a parameter, that is, there is a different function $+_n$ for each $n$.

A nullary function returning any single constant can be constructed by composing $+_n$ with the zero function 
\begin{equation} c_n() := 0 + n. \end{equation}

From now on we will just write the number $n$ to mean the function $c_n$, when it is not likely to lead to confusion.

The rest of this section consists of descriptions of operations and their formal definitions.

Decrement by 1:
\recur{
	dec(0) &:= 0, \\
	dec(n+1) &:= n.
}

Proper subtraction:
\recur{
	x \psub 0 &:= x, \\
	x \psub (y+1) &:= dec(x \psub y).
}

$x \psub y$ is bounded by $P_2^1 \equiv x$, so $\psub$ belongs to \grz{0}.

Signature:
\recur{
	sg(0) &:= 0, 	\\
	sg(x+1) &:= 1.
}

Reverse signature:
\recur{
	\rsg(0) &:= 1, \\
	\rsg(x+1) &:= 0.
}

Logical AND:
\recur{
	x \wedge 0 &:= 0,	 \\
	x \wedge (n+1) &:= x.
}

$\wedge$ is bounded by $P_2^1 \equiv x$, so is in \grz{0}.

Logical OR:
\recur{
	x \vee 0 &:= x, 		\\
	x \vee (n+1) &:= 1.
}

$\vee$ is bounded by $s \circ P_2^1 \equiv x+1$, so is in \grz{0}.

Logical NOT:
\begin{equation} \neg x := \rsg(x). \end{equation}

Ordering:
\begin{equation} \begin{split} 
	x > y &:= x \psub y, 	\\
	x < y &:= y \psub x, \\
	x \geq y &:= \neg (y<x),	\\
	x \leq y &:= \neg (x>y).
\end{split} \end{equation}

Equality:
\begin{equation} x=y := (x \leq y) \wedge (y \leq x) \end{equation}

The smallest of two numbers:
\begin{equation} \min(x,y) := x \psub ( x \psub y). \end{equation}

The remainder when dividing $x$ by $y$:
\recur{
	0 \bmod{y} &:= 0,	\\
	(x+1) \bmod{y} &:= \operatorname{rm}' \left( y \psub \left( (x \bmod{y}) + 1 \right), x \bmod{y} \right).
	}
\recurN{
	\operatorname{rm}'(0,y) &:= 0, 	\\
	\operatorname{rm}'(x+1,y) &:= y+1.
}
$\operatorname{rm}'$ is bounded by $y+1$ so belongs to \grz{0}. $x \bmod{y}$ is defined by recursion on \grz{0} functions and is bounded by $y$, so belongs to \grz{0}.

\subsection{\grz{1} functions}
Adding two numbers together is achieved by a recursion on the successor function.
\recur{
	x + 0 &:= x,			\\
	x + (y+1) &:= (x+y) + 1.
}
Because every function in \grz{0} is bounded by a function of the form $x+n$, where $n$ is a parameter, addition must belong to \grz{1} and not \grz{0}.

We can define another version of $+_n$ where $n$ is unbound:
\begin{equation} +_n(y) \equiv f_{+}(n,y) := n + y. \end{equation}
This version is in \grz{1}. This is really an abuse of notation, but it will be useful in a little while.

The biggest of two numbers:
\begin{equation} \max(x,y) := x + (y \psub x). \end{equation}

Note that $\max(x,y)$ is bounded by one of $P_2^1$ or $P_2^2$ but, since it could be either one of them, neither projection will serve as an \grz{0} bound on $\max$, so $\max(x,y)$ only belongs to \grz{1} and not \grz{0}.

The absolute difference of two numbers:
\begin{equation} |x - y| := (x \psub y) + (y \psub x). \end{equation}

Any constant multiple $n \cdot x$ is produced by $n$ iterations of addition:
\begin{equation} n \cdot x  \equiv 0 + x + \dots + x := +_x^{(n)}(0). \end{equation}

	So we can also construct any positive- and constant-coefficient linear polynomial $a_0 + a_1x_1 + a_2x_2 + \dots a_nx_n$ by finite compositions of \grz{1} functions. 

Remember that the functions we are considering have domain $\ZZ_{\geq 0}^d$, so computations involving subtraction can go wrong. The key point is that proper subtraction is not associative with addition. For example, $(4+3) \psub 5 \neq 4+(3 \psub 5)$. For polynomials with negative coefficients, computing all the positive terms and then subtracting the negative terms using proper subtraction will give the closest match to the actual value.

The quotient:
\recur{
	\left \lfloor \frac{0}{y} \right \rfloor &:= 0, \\
	\left \lfloor \frac{x+1}{y} \right \rfloor &:= \left \lfloor \frac{x}{y} \right \rfloor + \rsg\left( (x+1) \bmod{y} \right).
}

$x$ divides $y$:
\begin{equation} x \mid y := \rsg( x \bmod{y} ). \end{equation}

Bounded minimisation: 

\recur{
	\min_{i < 0} P(\xvec,i) &:= 0,	\\
	\min_{i < y+1} P(\xvec,i) &:= \left( \min_{i  < y} P(\xvec,i) \right) + sg\left( (\min_{i<y}P(\xvec,i))=y \wedge (P(\xvec,y) = 0) \right).
}

Given a predicate $P(\xvec,i)$ and a bound $y$, this returns the least $i<y$ such that $P(\xvec,i)$ is true. If there is no such $i$, $y$ itself is returned.

Bounded maximisation:
\recur{
	\max_{i < y} P(\xvec,i) &:= y \psub \min_{i < y} P'(\xvec, y, i), \\
	P'(\xvec,y,i) &:= P(\xvec, y \psub i).
}

If $P$ is an \grz{1} function then so are bounded minimisations and maximisations over $P$, because they are defined by a recursion over \grz{1} functions, bounded by $y$.

\begin{lemma}
	Let $A = \{a_0, a_1, \dots\} \subseteq \ZZ_{\geq 0}$ be a strictly monotonically increasing integer sequence. Define a function $\sigma_A : \ZZ_{\geq 0} \to A$ such that $\sigma_A(n) = a_n$.
	
	If $\sigma_A$ is \grz{n}-computable, $n \geq 1$, then its inverse $\sigma_A^{-1} : a_n \mapsto n$ is also \grz{n}-computable. 
\end{lemma}
\begin{proof}
	Since $A$ is monotonically increasing, $a_n \geq a_0 + n \geq n$. So we can construct $\sigma_A^{-1}$ through bounded minimisation on $\sigma_A$.

	\[ \sigma_A^{-1}(n) := \min_{i < n+1}{\left( \sigma_A(i) = n \right)} \]

	Constructed this way, $\sigma_A^{-1}$ is \grz{n}-computable since the function performing the bounded minimisation is \grz{1}-computable and the equality predicate is \grz{0}-computable. 
\end{proof}

Note that $\sigma_A^{-1}$ has as its domain all of $\ZZ_{\geq 0}$ but, since it is not being used to decide membership of $A$, we don't care what value it takes on inputs not in $A$.

\subsection{\grz{2} functions}
Multiplication is an unbounded recursion on the addition operation:
\recur{
	x \cdot 0 &:= 0,				\\
	x \cdot (y+1) &:= (x \cdot y) + x.
}

We can calculate $x^n$, when $n$ is constant, by $n$ compositions of multiplication by $x$, and hence any (positive-coefficient) polynomial can be obtained by finite compositions of addition and multiplication. So polynomials are \grz{2}-computable.

Finite sum:
\recur{
	S_f(\xvec,0) \equiv \sum_{i < 0} f(\xvec, i) &:= 0,		\\
	S_f(\xvec,y+1) \equiv \sum_{i < y+1} f(\xvec,i) &:= f(\xvec,y) + \sum_{i < y} f(\xvec,i).
}

Note that the level of the sum in the hierarchy really depends on the level of $f(\xvec,i)$. However, we can say that if $f$ is in \grz{n+2} then $S_f(\xvec,y)$ is also in \grz{n+2} because it entails $y-1$ additions. If $y$ is a bound variable and $f$ is in \grz{1}, then we could even place the sum in \grz{1} by constructing the sum through $y$ compositions of addition.

Bounded existential quantifier:
\begin{equation} \exists_{i < y} P(\xvec,i) := \sum_{i < y} P(\xvec,i). \end{equation}


Definition by cases: if  $P_i(\xvec)$, $0 \leq i \leq k$ is a finite collection of mutually exclusive, exhaustive predicates, then we can define
\[ f(\xvec) := \begin{cases}
	g_0(\xvec) & \textrm{if }P_0(\xvec),	\\
	\vdots & \vdots	\\
	g_k(\xvec) & \textrm{if } P_k(\xvec).
\end{cases} \]

In our language, this is:
\begin{equation} f(\xvec) := \sum_{i < k+1} g_i(\xvec) \cdot sg(P_i(\xvec)), \end{equation}
where $k$ is a parameter. If all the $P_i$ and $g_i$ are in \grz{n}, $n \geq 2$, then so is $f$, because we are just doing $k+1$ multiplications and additions.  

The integer square root function $\lfloor x^{\frac{1}{2}} \rfloor$ computes the greatest integer $n$ such that $n^2 < x$.

\[ \lfloor x^{\frac{1}{2}} \rfloor := \max_{n < x}{\left ( n \cdot n < x \right )} \]

\subsection{\grz{3} functions}
\grz{3} is where just about all the really useful operations are.

First of all, we can perform exponentiation by unbounded recursion on the multiplication operation:
\recur{
	x^0 &:= 1,				\\
	x^{y+1} &:= x \cdot x^y.
}

Factorial:
\recur{
	0! &:= 1,	\\
	(x+1)! &:= (x+1) \cdot x!.
}

Finite product:
\recur{
	P_f(\xvec,0) \equiv \prod_{i < 0} f(\xvec,i) &:= 1,	\\
	P_f(\xvec,y+1) \equiv \prod_{i < y+1} f(\xvec,i) &:= f(\xvec,y) \cdot \prod_{i < y} f(\xvec, i).
}
If $f$ is in \grz{3} then so is the product $P_f(\xvec,y)$, as it consists of $y-1$ multiplications. If $y$ is a parameter, then we can define the product using $y$ compositions of multiplication instead of the recursion, so if $f$ is in \grz{2} then the series product is too.

Bounded universal quantifier:
\begin{equation} \forall_{i < y} P(\xvec,i) := \prod_{i < y} P(\xvec,i). \end{equation}

Primality:
\begin{equation} x \textrm{ prime} :=  (x > 1) \wedge \forall_{z < x} \left( (z < 2) \vee \neg (z \mid x) \right). \end{equation}

The first prime after $x$:
\begin{equation} \operatorname{nextprime}(x) := \min_{i \leq x!+1} \left( (i \textrm{ prime}) \wedge (i > x) \right). \end{equation}
Note that this is an exceptionally inefficient way of finding primes, in terms of the number of computations performed. 

The \nth prime, starting at $n=0$:
\recur{
	p_0 \equiv p(0) &:= 2,		\\
	p_{n+1} \equiv p(n+1) &:= \operatorname{nextprime} (p_n).
}

The exponent of $x$ in the decomposition of $y$:
\begin{equation} [y]_x := \max_{i < y} \left( x^i \mid y \right). \end{equation}

\subsection{Lists}\label{sec:lists}

We will be working with $n$-tuples, or lists, extensively. All of the list operations can be defined as \grz{3} functions on numbers by way of the G\"odel encoding.

The G\"odel encoding of an $n$-tuple:
\begin{equation}\label{eq:ntuple} \xvec \equiv [x_0, \dots, x_{n-1}] := \prod_{i < n} p_i^{x_i+1}. \end{equation}
The $+1$ in the exponent is so we can reliably determine the length of a list by counting distinct prime factors (the empty list should be encoded as $1$: then it will have length $0$).
The bold $\xvec$ is shorthand so we don't have to write out the brackets formation. It shouldn't be confused with the use of $\xvec$ previously to mean an arbitrary number of parameters in a function application. An encoded list $\xvec$ is just a single number.

The value of the \ith position in an encoded list:
\begin{equation} (\xvec)_i := [\xvec]_{p_i} - 1. \end{equation}

The length of an encoded list:
\begin{equation} |\xvec| := \min_{i < \xvec} \left([\xvec]_{p_i} = 0  \right).\end{equation}
(Thus the length of $[x_0,\ldots, x_{n-1}]$ is $n$.)

The index of the first occurrence of a given value in an encoded list:
\begin{equation} \find(\xvec,y) := \min_{i < |\xvec|} (\xvec)_i = y. \end{equation}
Note that $\find(\xvec,y)$ returns $|\xvec|$ if $y$ does not occur in the list.

Whether an encoded list contains a given value:
\begin{equation} y \in \xvec := \find(\xvec,y) < |\xvec|. \end{equation}

The largest element of an encoded list:
\begin{equation} \operatorname{biggest}(\xvec) := \operatorname{biggest}'(\xvec,|\xvec|-1), \end{equation}
\recurN{
	\operatorname{biggest}'(\xvec,0) &:= (\xvec)_0, \\ 
	\operatorname{biggest}'(\xvec,n+1) &:= \max \left ( (\xvec)_{n+1},\operatorname{biggest}'(\xvec,n) \right ).
}

To obtain the sub-list of $\xvec$ starting at position $s$ and ending at position $e$:
\begin{equation} \xvec[s \dots e] \equiv \operatorname{slice}(\xvec,s,e) := \prod_{i=s'}^{e'}(p_{i-s'})^{(\xvec)_i+1}, \end{equation}
\begin{equation*} 
\begin{split}
	e' &:= \max(0,\min(e,|\xvec|-1)), \\ 
	s' &:= \max(0,\min(s,e')). 
\end{split}
\end{equation*}

To append a single value to the end of an encoded list:
\begin{equation} \operatorname{splice}(\xvec,n) := \xvec \cdot p_{|\xvec|}^{n+1}. \end{equation}

To concatenate two encoded lists:
\begin{equation} \xvec \concat \yvec := \operatorname{splice}(\xvec,(\yvec)_0) \concat \yvec[1 \dots |\yvec|-1]. \end{equation}

$\xvec \concat \yvec$ is bounded by $p_{|\xvec|+|\yvec|}^{(|\xvec|+|\yvec|) (\operatorname{biggest}(\xvec)+\operatorname{biggest}(\yvec))}$, so is \grz{3}-computable.

\section{Graphs \label{graphs}}

\begin{definition}
	Following \cite{Serre_1977}, a graph is a set of vertices $V$ and a set of directed edges $E = E^+ \cup E^-$, with two associated maps. The first,
\[ e \mapsto (\iota(e), \tau(e)), \]
associates each edge with its initial and terminal vertices. The second,
\[ e \mapsto \bar{e}, \]
is an involution on the edges, which must satisfy the conditions that $\bar{\bar{e}} = e$ and $\iota(\bar{e}) = \tau(e)$, $\forall e \in E$. We will write $e_{ij}$ to mean the edge with $\iota(e_{ij}) = i$ and $\tau(e_{ij})=j$. For any pair of opposing edges $e$ and $\bar{e}$, one is `positive' and belongs to $E^+$, and one is `negative' and belongs to $E^-$.
\end{definition}

\begin{definition}
A {\it path} in a graph is a sequence of edges $(e_1, e_2, \dots, e_n)$ such that $\tau(e_i) = \iota(e_{i+1})$, $1 \leq i < n$. A path is {\it reduced} if it does not contain an edge followed by its inverse, that is, if $e_{i+1} \neq \bar{e_i}$, $1 \leq i < n$. 
\end{definition}

\begin{definition}
A {\it circuit} is a path $(e_0, \dots, e_n)$ with $\iota(e_1) = \tau(e_n)$. 
\end{definition}

\begin{definition}
A graph is {\it connected} if there exists a path between each pair of its vertices.
\end{definition}

\section{Computable Trees \label{trees}}

\begin{definition}
A tree $T = (V,E)$ is a connected, non-empty graph with no reduced circuits.

Following \cite{Janson_2008}, a {\it rooted} tree has a particular vertex $v_0$ said to be at the `top' and called the {\it root}. The children of a vertex $v$ are those vertices adjacent to $v$ and further from the root than $v$. In an {\it ordered} tree, the set of children of each vertex is ordered, so there is a least, or {\it leftmost}, child, and the other children are greater, or on its right.
\end{definition}

\begin{definition}
An {\it ordered recursive tree} is a rooted, ordered tree obtained by a recursive process which begins with the root node and adds vertices below existing ones, in effect enumerating the edges.
\end{definition}

We can assign a labelling to an ordered recursive tree by giving vertices increasing integer labels corresponding to the order in which they were added to the tree, beginning with $0$ for the root. This way, the sequence of labels encountered on a path heading downwards is always increasing, and the root can always be recognised. 

Every edge $e_{ij}$ can be given a unique label $\max(i,j)$. 
If positive edges are defined to be the ones pointing downwards (away from the root) then the label of a positive edge $e_{i,j}$ is always $j$. For all 
edges $e$, both $e$ and $\bar e$  have the same label.

\begin{definition}
	Suppose we have a tree $T=(V,E)$ with root vertex $v_0$. $T$ is {\it \grz{n}-computable} if there is an \grz{n}-decidable labelling 
	\[i: V \rightarrow \ZZ_{\geq 0},\]
(we can insist that $i(v_0) = 0$) and an \grz{n}-computable `parent function',
\[\phi_T:i(V) \rightarrow i(V),\]
which gives the label of the parent of a vertex. For completeness, we also require that $\phi_T(v_0) = i(v_0) = 0$ and allow $\phi_T(v_0)$ to take any value on the complement of $i(V)$.
\end{definition}

\begin{definition}
	A finite ordered recursive tree can be entirely described in a canonical way by a {\it depth-first walk}. Note that every node has a single parent and a finite ordered set of children. Begin by `visiting' $v_0$. The process on `visiting' a vertex $v_i$ goes as follows: for each child node $v_j$, travel along $e_{ij}$ and `visit' $v_j$, then travel backwards along $\overline{e_{ij}}$. The sequence of labelled edges travelled along by beginning this process at $v_0$ is called the {\it depth-first walk} of the tree.
\end{definition}

Note that the root vertex's label will not appear in this sequence because it has no positive edge leading into it. 

Because an edge and its inverse have the same label, the first occurrence of a label in the sequence represents the positive edge, and the second occurrence represents the trip back up the negative edge.

The depth-first walk can be encoded as a G\"odel number by the method described in Section \ref{sec:lists}. We will define a function $\phi_{\tvec}(n)$ which takes an encoded depth-first walk $\tvec$ of a tree and gives the label of the parent of the 
vertex with label $n$. 

\subsection{Some functions to work with encoded trees}\label{encodetrees}

Let $\tvec$ be an encoded depth-first walk of a finite ordered tree.

To find the first and second occurrences of the edge with label $n$ in the walk:
\recur{
\operatorname{fst}(\tvec,n) &:= \find(\tvec,n), \\
\operatorname{snd}(\tvec,n) &:= \find\left( \tvec[\operatorname{fst}(\tvec,n)+1 \dots |\tvec|-1],n \right).
}

The function $\operatorname{find}$ is \grz{3}-computable, so the functions $\operatorname{fst}$ and $\operatorname{snd}$ are \grz{3}-computable.

To get the label of the \nth child of the root:
\recur{
\operatorname{child}(\tvec,0) &:= (\tvec)_0, \\
\operatorname{child}(\tvec,n+1) &:= (\tvec)_{\operatorname{snd}(\tvec,\operatorname{child}(\tvec,n))+1}.
}

The function $\operatorname{child}$ is constructed from \grz{3} functions and is bounded by the supremum of the labels of the vertices in the tree. As the tree is finite, $\operatorname{child}$ is \grz{3}-computable.

Note that the depth-first walk of the subtree descended from a vertex $v_n$ is the subsequence found between the two occurrences of $n$ in $\tvec$. 

To find the subtree descended from the \nth child node of the root:
\begin{equation} \operatorname{subtree}(\tvec,n) := \tvec[\operatorname{fst}(\operatorname{child}(\tvec,n))+1 \dots \operatorname{snd}(\operatorname{child}(\tvec,n))-1]. \end{equation}

The function $\operatorname{subtree}$ is constructed from \grz{3} operations so is \grz{3}-computable.

To obtain the number of children of the root node:
\begin{equation} \operatorname{kids}(\tvec) := \min_{i < \tvec} (\operatorname{child}(\tvec,i)=0). \end{equation}

The function $\operatorname{kids}$ is constructed by bounded minimisation on \grz{3} operations so is \grz{3}-computable.

To decide whether the root has a child with label $n$:
\begin{equation} \operatorname{haschild}(\tvec,n) :=  \left( \min_{i < \operatorname{kids}(\tvec)}({\operatorname{child}(\tvec,i)=n}) \right) < \operatorname{kids}(\tvec). \end{equation}


Finally, we present the parent function $\phi_{\tvec}$. The idea is basically to do the depth-first walk, remembering which vertex you just came from. If you reach a subtree which doesn't contain $n$ then turn back, or if you reach the required vertex then return the label of the vertex you just came from.

\recur{
\phi_{\tvec}(0) &:= 0, \\
\phi_{\tvec}(n+1) &:= \operatorname{p}'(\tvec,n+1,0).
}
\recurN{
\operatorname{p}'(\tvec,n,p) &:= \begin{cases}
						0 & n \not \in \tvec, \\
						p & \operatorname{haschild}(\tvec,n), \\
						\operatorname{p}'(\operatorname{subtree}(\tvec,z),n,\operatorname{child}(\tvec,z)) & \textrm{otherwise.}
					\end{cases}
}

\begin{equation*} z=z(\tvec,n) := \min_{i < kids(\tvec)}(n \in subtree(\tvec,i)). \end{equation*}

The function $\operatorname{p}'$ is \grz{3}-computable because it is bounded by $\tvec$.

We will also need to know if the tree contains an edge $e_{ij}$:
\begin{equation} e_{ij} \in \tvec \Leftrightarrow \left ( \phi_{\tvec}(i) = j \vee \phi_{\tvec}(j) = i \right ) \wedge i \neq j. \end{equation}


\begin{lemma}
A finite ordered tree is \grz{3}-computable.
\end{lemma}

\begin{proof}
	As the tree is finite, of course its labelling is an \grz{3}-decidable subset of $\ZZ_{\geq 0}$, and $\phi_{\tvec}$ as defined above is \grz{3}-computable.
\end{proof}

\section{Computable Groups \label{groups}}

Following \cite{Cannonito_1966}, we say a group $G$ is \grz{n}-computable if it has a triple of \grz{n}-computable functions $(i,m,j)$, such that

\begin{itemize}
	\item $i: G \rightarrow \ZZ_{\geq 0}$ is an injection of $G$ onto an \grz{n}-decidable subset of $\ZZ_{\geq 0}$;
	\item $m: i(G) \times i(G) \rightarrow i(G)$ computes the product of two group elements, i.e.\ $m \left(i(g_1),i(g_2)\right) = i(g_1g_2)$, $\forall g_1,g_2 \in G$;
	\item $j: i(G) \rightarrow i(G)$ computes the inverse of any element of $G$.
\end{itemize}

Note that $i$ itself is not computable but its image has computable characteristic function.

\begin{lemma}\cite[Lemma 3.1]{Cannonito_1973} \label{freegroupindex}
	A free group $F = \langle a_1, \dots \rangle$ on finitely or countably many generators is \grz{3}-computable.
\end{lemma}

The proof of the above lemma is not important for the purposes of this paper, but the index defined on the free group will be used later in this paper. The index $i(w)$ of a word $w = a_{i_0}^{\alpha_0} \dots a_{i_r}^{\alpha_r}$ is
\[ i(w) = \prod_{k=0}^r p_k^{J(i_k,\alpha_k)}. \]
$J(x,y)$ is an \grz{3}-computable integer pairing function $J:\ZZ_{\geq 0} \times \ZZ \rightarrow \ZZ_{\geq 0}$ defined by 
\[J(x,y)=((x+y)^2+x)^2+y\]
(see \cite{Cannonito_1973} for more details).

Cannonito and Gatterdam \cite{Cannonito_1973} introduced the {\it relativised Grzegorczyk hierarchy} relative to a set $A$, which includes the characteristic function of $A$ as a primitive function.

\begin{definition} \cite[Definition 2.3]{Cannonito_1973}
	Let $A \subset \ZZ_{\geq 0}$. Then the class of functions \grz{n}$(A)$ for $n \geq 2$ (with domain $\ZZ_{\geq 0}^k$ for arbitrary $k$ and range $\ZZ_{\geq 0}$) is the smallest class of functions, closed under composition and bounded recursion, containing all of \grz{n} in addition to 
	\begin{align}
		\chi_A(x) &:= \begin{cases}
									1 & \textrm{if}\; x \in A, \\
									0 & \textrm{if}\;  x \notin A.
							\end{cases}
	\end{align}
\end{definition}
\begin{lemma} \label{relativetonormalcomputable}
	Let $A \subset \ZZ_{\geq 0}$. If $c_A$ is \grz{m}-computable, then any \grz{n}$(A)$-computable function, $n \leq m$, is \grz{m}-computable.
\end{lemma}

\begin{definition}
	The {\it word problem} WP$(G)$, associated with a group $G$ with generating set $X$, is the set of all words $w \in X^{\ast}$ such that $w =_G 1$. That is, it is the set of all words representing the trivial element of $G$.
\end{definition}

\begin{theorem} \cite[Theorem 3.2]{Cannonito_1973} \label{wp-computable-implies-group}
	For every countable group $G$ there exists $A \subset \ZZ_{\geq 0}$ such that $G$ is \grz{3}$(A)$-computable. In particular, the word problem of $G$ is one such $A$.
\end{theorem}

\begin{corollary} \label{wp-iff-group}
	Let $G$ be a countable group with generating set $X$. Let $i_F$ be the index of $F(X)$ defined in \ref{freegroupindex}.
	
	$i_F(WP(G))$ is \grz{n}-decidable, $n \geq 3$, if and only if $G$ is \grz{n}-computable. 
\end{corollary}

\begin{definition}
	Let $H$ be a subgroup of an \grz{n}-computable group $G$. $H$ is {\it \grz{m}-decidable}, with $m$ necessarily larger than or equal to $n$, if the characteristic function of $i(H) \subseteq i(G)$ is \grz{m}-computable.
\end{definition}

	
\begin{definition}
 \ajd{Let $G_1$ and $G_2$ be \grz{n}-computable groups. }\cp{This isn't strictly necessary. For example, the identity homomorphism is always \grz{0}-computable, no matter what the $i_{G_1}$ and $i_{G_2}$ are.} \ajd{This returns
to the necessity to correctly define computable functions from $S$ to $T$, 
where $S\subseteq \ZZ_{\geq 0}^m$ and $T\subseteq \ZZ_{\geq 0}$. If 
$S$ and $T$ are not decidable then it makes no sense to talk of computable
functions from $S$ to $T$; and once  the grz-hierarchy comes in to play then
a function from $S$ to $T$ should only be \grz{n}-computable if $S$ and 
$T$ are \grz{n}-decidable. Otherwise there are \grz{n}-computable 
functions from undecidable sets $S$ to undecidable sets $T$. Even to
define the  constant function $f$ sending everything to $1$ between such 
sets may be impossible. You
can  define $f$ from $\NN$ to $\NN$, and then say that $f|_{S}$ (the
restriction of $f$ to $S$) is computable:   
but since you cannot say where it's defined that 
would be an unworkable definition of computable. To define the function
the characteristic function $\chi_S$ needs to be computable (at level n,
in case we're interested in the hierarchy). Likewise, if $T$ is undecidable
then you have no way in general of knowing whether 
$1$ lies in $T$ or not. You could say that if it does then the 
constant function is computable: and again you would be forced into
an unworkable definition of computable. $\chi_T$ must be (\grz{n}) computable 
to make such functions computable in any meaningful way. 
Therefore,
 something needs to be
added to Definition 2.1. to clear up what it means for a function from
$S$ to $T$, as above, to be \grz{n}-computable. (It should be something
to do with a partially defined function, with domain $S$ and range $T$,
as well as suitable conditions on $\chi_S$ and $\chi_T$.) This will then make
the definition of a \grz{n}-computable homomorphism what it should be.}
	A group homomorphism $\phi: G_1 \rightarrow G_2$ is \grz{n}-computable if there exists an \grz{n}-computable function $\hat{\phi}: i_1(G_1) \rightarrow i_2(G_2)$ such that
\[	\hat{\phi}(i_1(g)) = i_2(\phi(g)), \forall g \in G_1. \]
\end{definition}

\begin{comment}
		\begin{definition} \cite[Definition 3.3]{Cannonito_1973}
			A group $G$ is ``standard'' relative to an index $(i,m,j)$ if $i$ is defined by minimalisation from a presentation $1 \rightarrow K \rightarrow F \rightarrow G \rightarrow 1$ for $F$ free on at most countably many generators, $n \geq 3$, and $A \subset \ZZ_{\geq 0}$.
		\end{definition}

		\begin{theorem} \cite[Theorem 3.4]{Cannonito_1973}
			If $G$ is finitely generated and \grz{n}$(A)$ for $n \geq 3$ then any standard index of $G$ is \grz{n}$(A)$.
		\end{theorem}
\end{comment}

\section{Computability of Bass-Serre groups \label{bass-serre}}

Let $\Gamma = (V,E)$ be a connected graph. 

\begin{definition}
Associate with each vertex $v$ a vertex group $G_v = \present{X_v}{R_v}$, with the $X_v$ all pairwise disjoint. Call the set of all vertex groups $\mathbf{G}$. 

To each edge $e \in E$ associate two isomorphic {\it edge groups} $A_e \leq G_{\iota(e)}$ and $B_e \leq G_{\tau(e)}$, with $A_e = B_{\bar{e}}$, and an isomorphism $\phi_e : A_e \rightarrow B_e$ satisfying $\phi_e^{-1} = \phi_{\bar{e}}$.

$(\mathbf{G},\Gamma)$ is called a {\it graph of groups}.
\end{definition}

\begin{definition}
	Let $T$ be a spanning tree of $\Gamma$ (a subtree of $\Gamma$ containing every vertex), with a root vertex $v_0$. Then the {\it fundamental group} \cite{Serre_1977} of $(\mathbf{G},\Gamma)$, with respect to $T$ and $v_0$, is the group $G = \fgoagog$, defined as follows.

The generators of $G$ are
\[ X = \left( \bigcup_{v \in V}X_v \right) \cup \left( \bigcup_{e \in E}\{e\} \right),\]
and the relations are 
\[ R = \left( \bigcup_{v \in V}R_v \right) \cup \{e^{-1}ae = \phi_e(a),  \forall a \in A_e, \forall e \in E\} \cup \{ e^{-1} = \bar{e}, \forall e \in E\} \cup \{ e = 1, \forall e \in T \}.\]

$G$ can also be defined as the free product of all the vertex groups and the free group on the graph's edges minus the spanning tree, with the appropriate edge groups amalgamated.

\begin{equation}
G = \fgoagog = \left( \ast_{v \in V} G_v \right) \underset{\phi_e}{\ast} F(E(\Gamma \setminus T))
\end{equation}

\end{definition}

\begin{definition}
A word $w \in X^{\ast}$ is {\it admissible} if it can be factored in the form
\[ w = a_0 e_1 a_1 e_2 \dots a_{n-1} e_n a_n \]
where $(e_1,\dots,e_n)$ is a circuit in $\Gamma$ with vertex sequence $(v_0,\dots,v_n)$, such that $v_0 = v_n$, $v_i = \iota(e_{i+1})=\tau(e_i)$, $0 < i < n$, and $a_i \in G_{v_i}$, $i=0,\dots,n$. The sequence $(a_0,e_1, \dots, a_{n-1},e_n,a_n)$ is an {\it admissible sequence} for $w$.
\end{definition}

It will be more convenient from now on to refer to $G_{v_i}$ by $G_i$.

\begin{lemma}
	\label{trivialnormalform} \cite[Proposition 2.4]{Kapovich_2005}
Let $w \in X^{\ast}$ be an admissible word, and suppose $w =_G 1$. Then either:
\begin{itemize}
	\item $n=0$ and $a_0=1$ in $G_{v_0}$, or
	\item $n > 0$ and there exists $0<i<n$ such that $e_{i+1}=\bar{e_i}$ and $a_i \in B_{e_i}$.
\end{itemize}
\end{lemma}

\begin{definition}
Let $\phi_T(n)$ be the parent function for $T$. The path in $T$ from $v_i$ to $v_j$ can be found by freely reducing the path $\psi(i,j)$, defined by:
\begin{equation}\begin{split}
\psi(0,0) &:= \epsilon, \\
\psi(i,0) &:= (e_{i,\phi_T(i)}) \cdot \psi(\phi_T(i),0), \\
\psi(0,i) &:= \psi(i,0)^{-1}, \\
\psi(i,j) &:= \psi(i,0) \psi(0,j).
\end{split}\end{equation}

The free reduction of $\psi(i,j)$ will be implicit from now on.

What we really want is a function $\pi:G \rightarrow X^{\ast}$ such that $\pi(g)$ is an admissible word which represents $g \in G$ and whose circuit begins and ends at $v_0$.

If $g$ belongs to some $G_{v_i}$, then $\pi(g) = \psi(0,i) \cdot g \cdot \psi(i,0)$. Otherwise, if $g = e_{ij}$, some edge letter, then $\pi(e_{ij}) = \psi(0,i) \cdot e_{ij} \cdot \psi(j,0)$.
\end{definition}

\begin{lemma}
	Let $w = x_1 \dots x_n$ be a word in $X^{\ast}$, representing the group element $g \in G$. Then by replacing each generator $x_i$ by $\pi(x_i)$ and freely reducing the resulting word, we obtain an admissible word starting at $v_0$ which is equivalent to $w$. Call this word $\pi(w)$.
\end{lemma}

\begin{proof}
The new word is equivalent to $w$ because the only letters we are adding are edge letters from the spanning tree, which are all trivial in the presentation of $G$. Also, it is admissible since each $x_i$ in $w$ is replaced by an admissible word with circuit starting and ending at $v_0$.
\end{proof}

\begin{theorem} \label{fgoagogcomp}
Suppose we have $G = \fgoagog$, where $\Gamma$ has $\nu$ vertices. Suppose 
all the $G_i$ are finitely generated \grz{n}-computable groups for $n \geq 3$. Assume all the edge groups are \grz{n}-decidable, and all the isomorphisms $\phi_e$ are \grz{n}-computable. Then $G$ is \grz{n+1}-computable.
\end{theorem}

\begin{proof}
	We will show that the word problem of $G$ is \grz{n+1}-decidable. We can assume that the generating sets of all the vertex groups $G_v$ are disjoint, and that there is an \grz{n}-computable structure $(i_v,m_v,j_v)$ associated with 
each $G_v$.

Encode the depth-first walk of the spanning tree $T$ as a G\"odel number $\tvec$ per Section \ref{encodetrees}. Then the vertex-parent function $\phi_{\tvec}$ is \grz{3}-computable. From now on each vertex group can be referred to by the integer label of the vertex it belongs to.

We will define $i(F(X))$, an index of the free group on the generators of $X$, and use that to decide the word problem of $G$. First, we must assign numbers to the generators of $G$. Let $i_X(g)$ denote the number corresponding to the generator $g$. We will begin by using the first $\nu^2$ numbers to represent potential edges. For $0 \leq a,b \leq \nu - 1$ define $i_X(e_{a,b}) := a \cdot \nu + b$.

Each vertex group $G_i$ has a generating set $X_i$. For each $x_{i,j} \in X_i$, define $i_X(x_{i,j}) := \nu^2 + J(i,j)$.

Now that every generator has been given an integer label, $i(F(X))$ works the same way as the ``standard'' free group index described in \cite[Lemma 3.1]{Cannonito_1973} -- elements of $F(X)$ are freely-reduced words, encoded as G\"odel lists.

Given a word $w$, we wish to decide whether $w =_G 1$. First, compute $w' = \pi(w)$. We now need to split $w'$ into an admissible sequence $(a_0,e_1,\dots,e_n,a_n)$.

To do this, we must decide for each letter in $w'$ either which vertex group it is from or if it is an edge letter. Assign to each letter $w_i$ of $w'$ a code as follows: If $w_i$ belongs to $G_i$, then its code is $i$. If it is an edge letter, then its code is $\operatorname{biggest}(\tvec)+1$. We can then define an \grz{3}-decidable equivalence relation $\approx$ on the indices of the elements of $G$, whose equivalence classes correspond to the vertex groups plus one more for each edge letter. 
\ajd{One for the set of edges?}

\ajd{To see you 
have an edge you can 
use the fact that, for all elements $a\in X$, $a$ is an edge if and 
only if $i_X(a)\le \nu^2-1$. For other letters the left inverse function
$L$ of  $J$ is needed isn't it?}

\cp{No, we still want to split up different edges into different syllables.}
\ajd{What I was worrying about  here was the need to mention the
functions $R$ and $L$.  
I think you are starting with $w$ a sequence of encoded letters, using
the index $i$.
  If so, 
you have  an encoded list and  the elements of this
list which come from vertex groups are of the form $J(a,b)$, where $a$ is a vertex 
and $b$ is a generator of $G_a$. To find $a$ and $b$ you need the 
functions $L$ and $R$. I'm not sure if you need say this, and in any
case this is not the best place to make such a remark. If it's atall
necessary it should probably be part of the description of the standard free 
group index in section 5. There was a similar comment below, which
you've incorporated, about $L$ and $R$, and if this stays in then $L$
and $R$ need to be defined.} 

As $\approx$ has finitely many equivalence classes, and they are all \grz{3}-decidable, $\approx$ is \grz{3}-decidable.

Each letter $w_i$ in $w$ can then be replaced by $\pi(w_i)$. When working on the encoded version of $w$, this process is \grz{3}-computable, since $\phi_{\tvec}$ is \grz{3}-computable, and we only want to go as far as producing a list of generators, not a single element of $i(G)$. By concatenating all of the $\pi(w_i)$, we will create an admissible word equivalent to $w$.

The next task is to split $w'$ into `syllables', or contiguous subwords. A syllable is either a single edge letter or a word from one of the vertex groups.

From now on, let $\wvec$ be an encoded admissible word.  We will explain how to construct an encoded admissible sequence for $\wvec$.

Define a function which gives the position of the start of the syllable to which $(\wvec)_i$ belongs:
\recur{
	\operatorname{backtrack}(\wvec,0) &:= 0, \\
	\operatorname{backtrack}(\wvec,i+1) &:= \begin{cases}
																					i+1	&	(\wvec)_{i+1} < \nu^2, \\
																					i+1	&	(\wvec)_i \not \approx (\wvec)_{i+1}, \\
																					\operatorname{backtrack}(\wvec,i)	&	(\wvec)_i \approx (\wvec)_{i+1}.
																				\end{cases}
}

The function $\operatorname{backtrack}$ is constructed from \grz{3}-computable operations and is bounded by $|\wvec|$, so is itself \grz{3}-computable.

Now, the start of the \nth syllable is given by:
\recur{
\operatorname{start}(\wvec,0) &:= 0, \\
\operatorname{start}(\wvec,n+1) &:= \min_{\operatorname{start}(\wvec,n)+1 \leq i < |\wvec|} (\operatorname{backtrack}(\wvec,i) \neq \operatorname{start}(\wvec,n)).
}

The number of syllables can be computed like so:
\begin{equation} \operatorname{numsyllables}(\wvec) = \min_{i < |\wvec|} ( \operatorname{start}(\wvec,i) = |\wvec|). \end{equation}

And now the \nth syllable itself can be found:
\begin{equation} \operatorname{syllable}(\wvec,n) = \wvec[\operatorname{start}(\wvec,n) \dots \operatorname{start}(\wvec,n+1)-1]. \end{equation}

The function $\operatorname{syllable}$ is constructed from \grz{3}-computable functions and is bounded by $\wvec$ so is \grz{3}-computable.

We can then use the conditions of Lemma \ref{trivialnormalform} to determine if $\wvec$, encoded as $\wvec' = (a_0,e_1, \dots, e_n, a_n)$, is trivial.

If $n=0$, then $w'=1 \Leftrightarrow a_0=1$, which is an \grz{n}-decidable question.

If $n>0$, then we need to find a sequence of the form $e^{-1}A_ee$ or $eB_ee^{-1}$. The first of these is given by
\begin{equation}
\begin{split}
	\min_{i < \operatorname{numsyllables}(\wvec')-2} \; (
		&  (\operatorname{syllable}(\wvec',i) = e \in E) \wedge \\ 
		& ( \operatorname{syllable}(\wvec',i+1) \in B_e ) \wedge \\ 
		& ( \operatorname{syllable}(\wvec',i+2) = \operatorname{syllable}(\wvec',i)^{-1} ) 
	)
\end{split} 
\end{equation}
(and the same the other way round for $A_e$.) Note that since the first syllable must be an edge letter, we can say the last syllable is the inverse of the first by checking its length is 1, then computing its inverse,which is a matter of applying the inverses $L$ and $R$ of the pairing function $J$. We don't need to know how to compute the whole multiplication table to do this.

To decide if the middle syllable, which is a word on the encoded generators of some vertex group $G_v$, belongs to the appropriate edge group, it must be rewritten using the original index and multiplication function of $G_v$ provided in the setup, which is an \grz{n} operation. Once the word is in this form, membership of the edge group can be decided via an \grz{n} operation, by the assumptions of the theorem statement.

If the result of that calculation is $\operatorname{numsyllables}(\wvec')-2$ then $w$ is not trivial. Otherwise, we can replace the found sequence $eB_ee^{-1}$ with $\phi_e(\operatorname{syllable}(\wvec',i+1)$, and try again. The new word is still admissible and has fewer syllables than the original one, so repeated applications of this process will eventually lead to a word of one syllable or a negative answer. Because $\phi_e$ might increase the index of the word, this recursion means the process is only computable on the next level of the Grzegorczyk hierarchy.

So the word problem $WP(G)$ is \grz{n+1}-decidable, and hence $G$ is \grz{n+1}-computable by Corollary \ref{wp-iff-group}.
\end{proof}

Theorems \cite[4.6]{Cannonito_1973} and \cite[5.3]{Cannonito_1973} follow as corollaries of the above result, as free products with amalgamation and HNN extensions can be considered as the fundamental groups of graphs with one edge connecting two vertices and one vertex, respectively.

\begin{lemma}\label{primedist}
The $n$th prime $p_n \approx n \log n$.
\end{lemma}
\begin{lemma}\label{expine3}
$\exp(x,y) := x^y \in $ \grz{3}.
\end{lemma}
\begin{lemma}\label{godelbound}
The G\"odel encoding of any word of length $n$ on a finite alphabet is bounded above by $p_n^{J(n,n)}$, an \grz{3} function.
\end{lemma}

\begin{corollary}

In addition to the  assumptions of Theorem \ref{fgoagogcomp}, also assume that the edge groups are finitely generated: so each edge homomorphism $\phi_{e_{ij}}$ sends a finitely generated subgroup $E_{ij} \leq G_i$ to another finitely generated subgroup $E_{ji} \leq G_j$.

Then $G = \pi_1(\mathbf{G}, \Gamma, T, v_0)$ is \grz{n}-computable.

\end{corollary}

\begin{proof}

In the algorithm from Theorem \ref{fgoagogcomp}, the potential for unbounded recursion comes from applying the edge homomorphisms repeatedly. We will show that in this case the result of applying the edge homomorphisms repeatedly is bounded by an \grz{3}-computable function.

Let $w$ be a word on $G$ of length $n$. An upper bound on the number of syllables in $w$ is $n$, so let's say there are $n$ applications of edge homomorphisms.

A homomorphism $\phi_{e_{ij}}$ rewrites generators $x \in X_i$ as words $\phi_{e_{ij}}(x) \in X_j^{\ast}$. As $G_i$ is finitely generated, there is a word $\phi_{e_{ij}}(x)$ of maximum, finite, length $k_{ij}$. So a word $w_i \in E_{ij}$ of length $m$ is rewritten to a word $w_j \in E_j$ of length at most $k_{ij}m$.

Because the graph is finite, we can find a greatest $k \in \{k_{ij}\}$. So after reducing all the syllables (assuming that can be done for the input word), the resulting word in $G_0$, the group attached to the graph's root vertex, has length at most $k^n n = L$.

Hence the index of the resulting word is bounded by

\[ p_{k^nn}^{J(k^nn,k^nn)},\]

an \grz{3} function, by Lemma \ref{godelbound}. So recursion on the edge homomorphisms is bounded by an \grz{n} function, and so $G$ is \grz{n}-computable.

\end{proof}

\begin{corollary}
There exists a graph of \grz{3}-computable groups whose fundamental group is \grz{4}-computable.
\end{corollary}

\begin{proof}
Let $G_0 = \langle x,y \rangle$ and $G_1 = \langle a,b \rangle$  
be two copies of the free group on two generators. Let $(\mathbf{G},\Gamma)$
 be the graph of groups with $\mathbf{G} = \{G_0,G_1\}$ and $\Gamma$ the 
graph
with a single edge $e$ from $v_0$ to $v_1$; so $\Gamma = T = (\{v_0,v_1\},\{e,\bar{e}\})$.

Let $E_{01} = \left \langle \{x^{-n}yx^n, n \in \mathbb{N} \} \right \rangle$, 
$E_{10} = \left\langle \{ a^{-n}ba^n, n \in \mathbb{N} \} \right\rangle$ be the 
(infinitely generated) identified subgroups of $G_0$ and $G_1$, respectively.
In fact the given generators of the edge subgroups freely generate
these subgroups. This means that a homomorphism can be defined merely
by defining the images of the generators.

We begin by defining the homomorphism $\phi_e$ for the generators of $G_0$ with even powers of $x$:
\[	\phi_{e}(x^{-2n}yx^{2n}) := a^{-(n!)}ba^{n!}, \forall n \in \NN. \]

Next we define a function to decide membership of the set of factorial numbers, $\{d!, d \in \ZZ_{\geq 0}\}$. \recur{
\operatorname{fi}(n) &:= \operatorname{fi}'(n,n).\\
\operatorname{fi}'(n,0) &:= 0, \\
\operatorname{fi}'(n,d+1) &:= 
	\begin{cases} 
		d+1, & (d+1)! = n, \\
		\operatorname{fi}'(n,d), & (d+1)! \neq n.
	\end{cases}
}

Helpfully, $\operatorname{fi}$ also acts as the inverse of the factorial operation, since it returns the integer $d$ such that $n = d!$, when such a $d$ exists.

The function $\operatorname{fi}(n)$ is \grz{3}-computable since it is bounded by $n$ and is constructed from \grz{3}-computable functions.

In order for $\phi_e$ to be an isomorphism, we need to identify the remaining generators of $G_0$ (those with odd powers of $x$) with the remaining generators of $G_1$ (those with non-factorial powers of $x$).

To do that, we need a bijection between $\NN$ and the the non-factorial numbers.

Define 
\recur{
	\operatorname{nf}(1) &:= 3, \\
	\operatorname{nf}(n+1) &:= 
		\begin{cases}
			\operatorname{nf}(n)+1, & \neg(\operatorname{fi}(\operatorname{nf}(n)+1)), \\
			\operatorname{nf}(n)+2, & \operatorname{fi}(\operatorname{nf}(n)+1).
		\end{cases}
}

Again, $\operatorname{nf}(n)$ is \grz{3}-computable. Its inverse is also \grz{3}-computable since $\operatorname{nf}^{-1}(n) = \min_{i<n} (\operatorname{nf}(i) = n)$.

Define
\[ \phi_{e}(x^{-(2n-1)}yx^{2n-1}) := a^{-\operatorname{nf}(n)}ba^{\operatorname{nf}(n)}, \forall n \in \NN. \]

Now we can define $\phi_{\bar{e}}$ to be the inverse of $\phi_e$.
\[ 
	\phi_{\bar{e}}(a^{-n}ba^n) := 
		\begin{cases}
			x^{-2 \cdot \operatorname{fi}(n)}yx^{2 \cdot \operatorname{fi}(n)}, & \operatorname{fi}(n), \\
			x^{-\operatorname{nf}^{-1}(n)}yx^{\operatorname{nf}^{-1}(n)}, & \neg \operatorname{fi}(n).
		\end{cases}
\]

Note that since $G_0$ and $G_1$ are \grz{3}-computable, the edge isomorphism is \grz{3}-computable in both directions.

Construct the index for $G = G_0 \underset{\phi_e}{\ast} G_1$ by following the method in \ref{fgoagogcomp}.

Consider a word $w$ of the form
\[ w = ea^{-1}e^{-1} \dots x^{-1}ea^{-1}e^{-1}x^{-2n}yx^{2n}eae^{-1}x \dots eae^{-1}. \]

In order to decide if this word is trivial, it must be simplified to something of the form $x^{-m}yx^m$. Start with the central subword $x^{-2n}yx^{2n}$. Each conjugation of $x^{-2n}yx^{2n}$ by $eae^{-1}x$ causes the number $2n$ to be raised to (roughly) the factorial of itself. 
Since there can be arbitrarily many such conjugations, the final value of $m$ will not be bounded by any \grz{3} function.

As $m$ depends on the input, the length of the simplified word can only be computed by unbounded recursion on an \grz{3} function, so is \grz{4}-computable and not \grz{3}-computable. 

Hence, the word problem of $G$ is \grz{4}-computable, and by Corollary \ref{wp-iff-group}, $G$ is \grz{4}-computable. 
\end{proof}

\section{Stallings' pregroups and their universal groups}
\label{sec:pregroup}

We now turn to the notion of pregroups in the sense of Stallings,
\cite{Stallings_1971}, \cite{Stallings_1987}.
A \emph{pregroup} $P=(P,D,m,\eps,~^{-1})$ consists of a set $P$,  a distinguished element
$\eps$, a subset $D\subset P\times P$,  
equipped with  a partial multiplication %, that is a function
$m:D \to P$, $(a,b) \mapsto ab$, 
and an involution (or \emph{inversion}) %, that is a function
$P \to P$, $a \mapsto a^{-1}$, satisfying the following axioms
for all $a,b,c,d \in P$. (By ``$ab$ is defined'' we mean to say that
$(a,b)\in D$ and $m(a,b)=ab$.)
\begin{enumerate}[(P1)]
\item  %for all $a \in P$
$a \eps$ and $\eps  a$ are defined and
$a \eps = \eps a = a;$
\item  %for all $a \in P,~$
$a^{-1} a$ and $a a^{-1}$ are defined and $ \ \
a^{-1} a = a a^{-1} = \eps;$
\item  % for all $a, b \in P,$
if $ a b$ is defined, then so is
$b^{-1} a^{-1},$ and
$(a  b)^{-1} = b^{-1} a^{-1};$
\item  \label{it:P4}%for all  $a, b, c \in P,$
if $a  b$ and $b
c$ are defined, then $(a b) c$ is defined if and only if $a (b
c)$ is defined, in which case
$$ (a b) c =  a (b c);$$
\item   \label{it:P5} %for all $a,b,c,d \in P$
if $a  b, b  c,$ and $c  d$
are all defined then either $a  b  c$ or $b
c  d$ is defined.
\end{enumerate}
It is shown in \cite{Hoare_1988}
that (P3) follows from (P1), (P2), and (P4), hence can be omitted.
From now on, when we write $ab=c\in P$, we mean that $a,b$ and $c$ are in $P$, 
$(a,b)\in D$ and $m(a,b)=c$. 

The \emph{universal group}  $\UP$  of the pregroup $P$ can be defined as the quotient
monoid
\begin{align*}
\UP = %P^*/\set{ab=c}{D(a,b)=c}.
P^*/\set{ab=c}{m(a,b)=c},
\end{align*}
where $P^*$ denotes the free monoid on $P$. Note that in $\UP$ the identity element 
$\eps \in P$ is identified
 with the empty word $1 \in P^*$.
The elements of $\UP$ may
therefore represented by
finite sequences $(a_1, \ldots, a_n)$ of elements
of $P$ such that $a_ia_{i+1}$ is not defined in $P$, for $1\leq
i<n$, and $a_i\neq \eps$, for all $i$. (The last condition
is necessary only to exclude the sequence $(\eps)$.)  
Such sequences are called {\em $P$-reduced} sequences.
Since every element in $\UP$ has an inverse, it is clear that
$\UP$ forms a group. 


If ${\Sigma}$ is any set, then
the disjoint union $P= \smallset{\eps} \cup \Sigma \cup \ov{\Sigma}$, 
where $\ov{\Sigma}=\{\bar a:a\in \Sigma\}$ is a copy of ${\Sigma}$, 
yields a pregroup with involution given by $\ov \eps=\eps$, $\ov{\ov{a}}=a$,
for all $a\in \Sigma$,  such that $p \ov{p} = \eps$,
for all $p\in P$.
In this case the universal
group $\UP$ is nothing but the free group $F(\Sigma)$.

The universal property of $\UP$ holds trivially, namely
the canonical morphism of pregroups $P \to \UP$ defines the
left-adjoint functor to the {forgetful}
functor from groups to pregroups.

\subsection{Stallings' Theorem}\label{sec:stall}
Stallings \cite{Stallings_1971} showed that composition of the
inclusion map $P \rightarrow P^\ast$
 with the standard quotient map $P^\ast \rightarrow \UP$ is injective,
where $P^\ast$ is the free monoid on $P$. His construction involves defining
an equivalence relation, which we shall now describe, on the set of 
$P$-reduced sequences.
First define the binary relation  $\sim$ on the set $P$-reduced sequences of elements
of $P$ by
$$(a_1,\ldots, a_i,a_{i+1},\ldots, a_n)\sim
(a_1,\ldots ,a_ic,c^{-1}a_{i+1},\ldots, a_n),$$
provided  $(a_i,c),(c^{-1},a_{i+1}) \in D.$
Then Stallings' equivalence relation $\approx$ is the transitive closure of $\sim$.
%%%%%%%%%%%%%%%%%%%%%%%%%% example

Canonical examples of pregroups arise from free products of groups with
amalgamation and HNN-extensions (see \cite{DiekertDuncanMiasnikov_2010} for details).


The following is the principal result on the universal groups of pregroups.

\begin{theorem} [Stallings \cite{Stallings_1971}]\label{thm:sup}
Let $P$ be a pregroup. Then:
\begin{enumerate}[1)]
\item Every element of $\UP$ can be  represented by
a $P$-reduced sequence;
\item  any two $P$-reduced sequences representing
the same element are $\approx$ equivalent, in particular they have the same length;\label{it:sup2}
\item $P$ embeds into  $\UP$.
\end{enumerate}
 \end{theorem}

If $\avec=(a_1,\ldots, a_i,a_{i+1},\ldots, a_n)$ is a word in $P^*$ and $a_ia_{i+1}=b\in P$ then
we say that the word  $(a_1,\ldots, b ,\ldots, a_n)$ is obtained from $\avec$ by
\emph{elementary} $P$-\emph{reduction}. We also say that the empty word $1$ is obtained from the 
word $(\eps)$, of length one, by elementary $P$-reduction. If $\bvec$ is obtained from a word $\avec$
 by a finite sequence of elementary $P$-reductions then we say that $\bvec$ is obtained from $\avec$
by $P$-\emph{reduction} and that $\bvec$ is a $P$-\emph{reduction} of $\avec$.  
(Note that, unless $\bvec=1$,  such a reduction can always be carried out without ever
replacing and occurrence of $\eps$ with $1$.) 
In particular the following lemma follows from statement \ref{it:sup2} of Theorem \ref{thm:sup}.
\begin{lemma}\label{lem:interleave}
Let $\cvec=(c_1,\ldots , c_m)$ and $\dvec=(d_1,\ldots, d_n)$ be $P$-reduced words. Then 
$\cvec=\dvec$ in $\UP$  if and only if $n=m$ and $1$ is a $P$-reduction of the word
$(d_m^{-1},\ldots, d_1^{-1},c_1,\ldots , c_m)$. 
\end{lemma}

If $\avec \in P^\ast$ and both $\bvec$ and $\cvec$ are $P$-reduced, $P$-reductions of $\avec$ then
it follows from Theorem \ref{thm:sup} that $\bvec\approx \cvec$. 

Rimlinger \cite{Rimlinger_1987a} (see also Rimlinger \cite{Rimlinger_1987b} and Hoare \cite{Hoare_1988}) 
has shown that, 
\begin{itemize}
\item given any graph of groups with fundamental group $G$, a pregroup $P$ may
be constructed such that $\UP = G$;  and conversely that
\item  given a pregroup $P$ which satisfies a condition called ``finite height'' then a graph
of groups with fundamental group $\UP$ may be constructed.
\end{itemize}
Not all pregroups have finite height, so there exist universal groups of pregroups which
are not  the fundamental groups of any  graph of groups. 

\subsection{Pregroups and the Grzegorczyk hierarchy}


Let $P=(P,D,m,\eps,~^{-1})$ be a pregroup and let $i$ be an injective function $i:P\maps \ZZ_{\geq 0}$.
 %(In this case $P$ must be countable.)  
Define 
\begin{itemize}
\item $D^\prime=
\{(x,y)\in \ZZ_{\geq 0}\times \ZZ_{\geq 0}\,:\, x=i(p), y=i(q), (p,q)\in D\}$,
\item 
the function 
$m^\prime:D^\prime \maps \ZZ_{\geq 0}$, such that $m^\prime(i(p),i(q))=i(m(p,q))$, 
for 
all $(p,q)\in D$,  
and 
\item the function $j$  given
by $j(i(p))=i(p^{-1})$, for all $p\in P$.
\end{itemize}
Then $P$ is said to have 
{\em index} $(i,m^\prime,j)$. 
\begin{definition}
The pregroup $P$ is \grz{n}$(A)$-\emph{computable}, with respect to
index $(i,m^\prime,j)$, if 
\be
\item $i(P)$ is \grz{n}$(A)$-decidable;
\item $D^\prime$ is \grz{n}$(A)$-decidable;
\item $m^\prime$ is \grz{n}$(A)$-computable and 
\item $j$ is \grz{n}$(A)$-computable.
\ee
\end{definition}
\ajd{Should results be stated for \grz{n}$(A)$ or just \grz{n}? From now on I'll drop $A$.}

%%%%%%%%%%%%%%%%%%%%%%% here

\begin{theorem}\label{thm:UPgrz} Let $P$ be a \grz{n}-computable pregroup. Then the universal group $\UP$ of $P$  
is \grz{n+1}-computable.
\end{theorem}

In order to prove this theorem we first introduce some functions and then use these to construct
an index for $\UP$. 

\subsection{Functions for pregroups}
In this section we shall use the notation and constructions  of
Section \ref{sec:lists}. As we shall mostly be working with encoded lists we use 
$\avec$ to represent both an encoded list $\avec$ or an arbitrary non-negative integer $\avec$, 
as appropriate to
the context. 
Let $i:P\maps \ZZ_{\geq 0}$ be an injective function and assume that $i(P)$ is \grz{n}-decidable.
We shall assume that $i(\eps)=1$.   
Elements of $P^*$ are regarded as finite sequences of elements of $P$, and 
usually referred to as \emph{words}.  Define an indexing function
$i_1:P^*\maps \ZZ_{\geq 0}$ by 
\begin{equation}\label{eq:imonoid}
i_1(a_0,\ldots,a_m):=[i(a_0),\ldots ,i(a_m)].
\end{equation} 
Then $i_1$ is injective; in particular, by definition of the
G\"odel number of the empty sequence,  
$i_1(1)=1$, while,  on the other hand, $i_1(\eps)= 4$.  

The function $i_1$ is 
 \grz{n}-decidable: the characteristic function of $i_1(P^*)$ is the function 
$\chi$ such that 
\[\chi(\avec):=\displaystyle{\bigwedge_{s=0}^{|\avec|-1}}(\avec)_s \in i(P).\]  

We also define functions corresponding to multiplication in $P^*$  and to the extension of the inversion
operation on $P$ to $P^*$. That is we define $m_1:\ZZ_{\geq 0}\times\ZZ_{\geq 0}\maps \ZZ_{\geq 0}$ and $j_1:\ZZ_{\geq 0}\maps \ZZ_{\geq 0}$ by
\begin{equation}\label{eq:mmonoid}
m_1(i_1(\uvec),i_1(\vvec)):=i_1(\uvec)\concat i_1(\vvec)) 
\end{equation}
and 
\begin{equation}\label{eq:jmonoid}
j_1(i_1(u_0,\ldots, u_m)):=i_1(j(u_m),\ldots ,j(u_0)). 
\end{equation}
Then $m_1$ and $j_1$ are \grz{n}-computable functions, $m_1((i_1(\uvec),i_1(\vvec))=i_1(\uvec\vvec)$ 
and $j_1(i_1(u_0,\ldots, u_m))=i_1(u_m^{-1},\ldots , u_0^{-1})$, as required.

Next we define functions to work with $P$-reduction of encoded words.
Define $\Dfind:\ZZ_{\geq 0}\maps \ZZ_{\geq 0}$ by 
\begin{equation}\label{eq:Dfind}
\Dfind(\avec):=\min_y(y<|\avec|\wedge ((\avec)_y,(\avec)_{y+1})\in D^\prime).
\end{equation}
As $D^\prime$ is \grz{n}-decidable and the minimisation is bounded this is
an \grz{n}-computable function. 

Next define the predicate $\Preduced$ on $\ZZ_{\geq 0}$ by
\begin{equation}\label{eq:Preduced}
\Preduced(\avec):=\left(\find(\avec,i(\eps))=|\avec|\right)\wedge
\left( \Dfind(\avec)=|\avec|\right).
\end{equation} 
Again this is \grz{n}-computable and we have $\Preduced(i_1(\uvec))=1$ if and 
only if $\uvec$ is a $P$-reduced word in $P^\ast$. 

Now we construct a function to perform $P$-reduction on an encoded word. This
function will perform elementary $P$-reduction at the leftmost position where
it is possible in a given word. As pointed out in Section \ref{sec:stall} the
order in which $P$-reductions are performed does not affect the equivalence
class of the $P$-reduced word that is produced, so there will be no need to
consider any other possible  sequences of $P$-reduction. 

Define a function $\leftm:\ZZ_{\geq 0}\maps \ZZ_{\geq 0}$ by
\begin{equation}\label{eq:leftm}
\leftm(\avec):=
\left\{
\begin{array}{ll}
1,& \textrm{ if } \avec = [1], \textrm{ or } [\eps]\\
\avec[0\cdots \Dfind(\avec)-1]\concat &\\
m^\prime((\avec)_{\Dfind(\avec)},(\avec)_{\Dfind(\avec)+1})\concat&\\
\avec[\Dfind(\avec)+2\cdots |\avec|-1] ,& \textrm{ otherwise. } 
\end{array}
\right.
\end{equation}


This is an \grz{n}-computable function. 

Now define $\Predn:\ZZ_{\geq 0}\times \ZZ_{\geq 0} \maps \ZZ_{\geq 0}$ by
\begin{align}
\Predn(\avec,0) & := \avec,\notag\\
\Predn(\avec, n+1) & := \leftm(\Predn(\avec,n))\label{eq:Pr}.
\end{align} 
As $\Predn$ is defined by primitive recursion using \grz{n}-computable functions it
is \grz{n+1}-computable. 
The recursion requires up to $n$ applications of $m^\prime(x,y)$, and we 
do not have 
a \grz{n}-computable bounding function for the recursion; so cannot say
whether or not $\Predn(\avec,n)$ is in \grz{n}.

Finally define $\Preduction:\ZZ_{\geq 0}\maps \ZZ_{\geq 0}$ by
\begin{equation}\label{eq:Preduction}
\Preduction(\avec):=\Predn(\avec,|\avec|).
\end{equation}
Now if $\uvec \in P^\ast$ and $\vvec$ is a $P$-reduced word 
obtained from $\uvec$ by $P$-reduction, where reduction is always made 
at the leftmost possible position, then $\Preduction(i_1(\uvec))=i_1(\vvec)$. 

In order to recognise when two encoded words represent elements of the same
$\approx$ equivalence class we define the relation $\Interleaven\subseteq \ZZ_{\geq 0}\times \ZZ_{\geq 0}$ 
defined as 
\begin{equation}\label{eq:interleaven}
\begin{split}
\Interleaven(\avec,\bvec) & :=\Preduced(\avec)\wedge \Preduced(\bvec) \\ 
&\wedge (|\avec|=|\bvec|)
\wedge \left( \Preduction(m_1(j_1(\bvec),\avec))=1\right).
\end{split}
\end{equation}
This is an \grz{n+1}-decidable relation and from Theorem \ref{thm:sup} and Lemma \ref{lem:interleave} we have,
for $P$-reduced words $\uvec$ and $\vvec$, 
$\uvec=\vvec\in \UP$ if and only if  $|\uvec|=|\vvec|$ and $\vvec^{-1}\uvec$ $P$-reduces to the
empty word,  if and only if $\Interleaven(i_1(\uvec),i_1(\vvec))$.  
We shall write $m\approx n$, for integers $m,n$ such that $\Interleaven(m,n)$. 
\subsection{Proof of Theorem \ref{thm:UPgrz}}

We define a function $i_2:\ZZ_{\geq 0}\maps \ZZ_{\geq 0}$ which will be used to construct an
index for $\UP$. 
\begin{equation}\label{eq:i2}
i_2(\avec):=\min_y(y<\avec \wedge (y\in i_1(P)) \wedge \Preduced(y) \wedge (y\approx \avec)).
\end{equation}
Now define functions $i_G:P^*\maps \ZZ_{\geq 0}$, 
$m_G:i_G(P^*)\times i_G(P^*) \maps \ZZ_{\geq 0}$
and $j_G:i_G(P^*)\maps \ZZ_{\geq 0}$ by 
\begin{align}
i_G(\uvec) &:=i_2i_1(\uvec),\\
m_G(\avec, \bvec)& :=i_2(\Preduction(m_1(\avec,\bvec))) \textrm{ and }\\
j_G(\avec)&:= i_2j_1(\avec),
\end{align}
for all for all $P$-reduced words $\uvec\in P^*$ and $\avec$, $\bvec \in i_G(P^*)$. 
Theorem \ref{thm:UPgrz} then follows from the next Proposition. 
\begin{proposition}
The group $G=\UP$ has \grz{n+1} index $(i_G,m_G,j_G)$. 
\end{proposition}

\begin{proof}
The group $G$ consists of equivalence classes of $P$-reduced words under the  relation $\approx$.
If $\uvec$ and $\vvec$ are $P$-reduced words with $\uvec\approx \vvec$ then 
$i_G(\uvec)=i_2i_1(\uvec)=i_2i_1(\vvec)=i_G(\vvec)$, by construction. Therefore $i_G$ is 
a well defined function on $G$.  Moreover if  $\uvec$ and $\vvec$ are $P$-reduced words
such that $i_G(\uvec)=i_G(\vvec)$ then both $\uvec$ and 
$\vvec$ are equivalent to $i_2i_1(\uvec)$, so $i_G$ is injective. Let $R$ be the set of 
$P$-reduced words and let $S$ be the image $i_G(R)$ of $R$ under $i_G$. Then, for $\xvec\in \ZZ_{\geq 0}$, 
\[\chi_S(\xvec)=(\xvec\in i_1(P_1)) \wedge \Preduced(\xvec) \wedge (i_2(\xvec)=\xvec),\]
so $\chi_S$ is \grz{n+1}-computable. Hence $i_G(R)=i_G(G)$ is \grz{n+1}-decidable. 

As $i_2$ is \grz{n+1}-computable, so are $m_G$ and $j_G$. It therefore remains to
show that, for all $\uvec,\vvec \in R$, 
\[m_G(i_G(\uvec),i_G(\vvec))=i_G(\uvec\cdot \vvec)\textrm{ and } j_G(i_G(\uvec))=i_G(\uvec^{-1}),\]
where $\uvec\cdot \vvec$ denotes the product of $\uvec$ and $\vvec$ in $G$. 

Let $\uvec_0$ and $\vvec_0$ be $P$-reduced words such that $i_G(\uvec_0)=i_2(i_1(\uvec_0))=i_1(\uvec_0)=
i_G(\uvec)$ and similarly $i_2(i_1(\vvec_0))=i_1(\vvec_0)=
i_G(\vvec)$. Let $\avec=i_1(\uvec_0)$ and $\bvec=i_1(\vvec_0)$; so $i_2(\avec)=\avec$ and 
$i_2(\bvec)=\bvec$.  
The product  $\uvec\cdot \vvec$ is the $\approx$ equivalence class of the
$P$-reduction of the concatenation of $\uvec$ and $\vvec$. Therefore 
$i_G(\uvec\cdot \vvec)=i_2(\Preduction(m_1(i_1(\uvec),i_1(\vvec))))$.  
Since $\uvec=_G \uvec_0$ and $\vvec=_G \vvec_0$, we have $\uvec\cdot \vvec=_G \uvec_0\cdot \vvec_0$, 
so  $\Preduction(m_1(i_1(\uvec),i_1(\vvec))= \Preduction(m_1(\avec,\bvec)).$ Hence 
$i_G(\uvec\cdot \vvec)=i_2(\Preduction(m_1(\avec,\bvec)))=m_G(\avec,\bvec)=m_G((i_G(\uvec),i_G(\vvec))$,
 as required.

A similar argument shows that $j_G(i_G(\uvec))=i_G(\uvec^{-1})$.
\end{proof}
\subsection{Questions}
\be
\item Under which conditions is $\UP$ \grz{n}-computable?
\item How does the index found in this section compare with that found for Bass-Serre groups in
earlier sections?
\item ....
\ee
\bibliographystyle{alpha}
\bibliography{grzegorczyk}

\end{document}
